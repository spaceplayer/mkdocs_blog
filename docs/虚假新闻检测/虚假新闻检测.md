# 多模态内容质量之假新闻

假新闻是一个微观领域问题, 和谣言分类, 事实判断, 标题党检测, 垃圾内容挖掘等都比较类似, 宏观上都属于内容质量的领域, 很多方法可以通用, 数据集可公用, 本文介绍几篇有代表性的假新闻论文, 从中学习多模态, 基于网络, 特征挖掘等任务在假新闻领域的一些实战。



## 模型构建

根据[Kai Shu, 2017]的划分, 模型在这里主要有两类, 1 基于内容的建模 2基于社交网络的模型。

### 1.基于内容的建模

有1.1面向知识和事实库的和1.2面向行文风格的

#### 1.1 面向知识库

​		事实检查系统有点类似谣言鉴别系统, 对文章描述的观点和客观事物进行较真, 类似QA系统是一个比较复杂的NLP领域, 包括知识表示, 知识推理。在知识库数据集上有几种划分方式: 

**1. 专家系统：**各个领域的专家构建的知识库， 显然这种方式的效率和扩展性都非常差。 不过如果是垂直类目（生物，历史）那或许可以在某个客观事实比较多的类目下进行尝试；

**2. 集体智慧：**用户集体知识的反馈来构建的一套知识库。

1 和 2 有了之后其实可以通过类似检索的方法，来对新的内容进行相似度判断，从而充分利用积累的历史内容提供出来的特征指示。

**3. 基于算法分类：**使用知识图谱或者事理图谱来对内容进行真实性判断，当前主要的开放知识图谱有 DB-pedia 和 Google Relation Extraction 数据集。

这个领域的问题，类似 NLP 的 QA 问题，有兴趣的同学可以参考 ***[Yuyu Zhang, 2017]\*** 的 VRN变分推理网络。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-09-124121.png)

作者通过概率模型来识别问句中的实体，问答时在 KB 上做逻辑推理，且推理规则将被学习出来。即可用于做事实判断。

当前这个方向技术落地成本高，难度较大，效果也不一定理想。

#### 1.2 面向内容风格

用文章内容本身的行文风格，通过上下文无关文法得到句子的句法结构，或者 RST 修辞依赖理论等其他 NLP 深度模型去捕捉句子文法信息。

根据捕捉文本信息描述种类的不同，作者分为两类，检测欺骗程度，检测描述的主观客观程度（越客观公正的可能性越大）两种。震惊体的标题党就属于这类。

其中，假新闻可能用到的特征，包括普通特征和聚合特征两大类。普通特征就是页面，文本，图片，标题等单纯的特征 embedding，聚合特征就是把各个普通特征进行组合和有监督的训练成一个一个子模型问题。然后这些子模型的输出又可以作为聚合特征用在假新闻领域。

下图就是我们使用的主要特征集：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-023747.png)

### 1.2 基于社交网络建模

分为两种，基于**立场**和基于**传播行为**的。

前者主要是基于用户对内容的操作（评论，点赞 ，举报等等）构建矩阵或者图模型。

而基于传播行为对对象建模，类似 PageRank 的行为传递。下面介绍的 ***News Verification by Exploiting Conflicting Social Viewpoints in Microblogs\*** 一文就是这种类型 。

1. 对虚假新闻的传播游走轨迹跟踪， 以及通过图模型和演化模型中针对特定假新闻的进一步调查；
2. 识别虚假新闻的关键传播者，对于减轻社交媒体的传播范围至关重要。

分叉传播：



***[Benjamin D. Horne and Sibel Adalı,2017]*** 通过手工构建了大量的特征，使用单因素方差分析和秩和检验对特征进行挖掘。 发现真新闻文章明显长于假新闻文章，假新闻很少使用技术词汇，更少的标点符号，更少的引号和更多的词汇是冗余的。另外标题也有明显的不同，假新闻的标题会更长，更喜欢增加名词和动词。真的新闻通过讨论来说服，假新闻通过启发来说服。

类似的内容分析还有：***Automatic Detection of Fake News***。

***[z.zhao et, 2018]*** 发现大多数人转发（红点）真实新闻是从一个集中的来源（绿点）。而虚假新闻通过人们转发其他转发者来传播的。

大多数人转发（红点）真实新闻是从一个，集中的来源（绿点）。而虚假新闻通过人们转发其他转发者来传播的。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-024847.png)



## **假新闻的4个研究方向**

***[Kai Shu, 2017]*** 文章总结了假新闻的几个主要的研究方向。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-024917.png)

**数据方面的研究工作：**现在还没有标准的测评数据集，这是需要去建立的。再有就是通过传播特性去更早的检测假新闻。另外一个就是从心理学角度去做假新闻的意图检测，这个角度过去往往被忽略。

**模型特征方面的研究工作：**往往会使用用户的画像特征，内容特征（NLP、CV）结合深度学习，还有传播网络特征，比如用户和内容之间的关系构造出来的网络特征，网络本身的 embedding 表现。

**模型方面的研究工作：**第一个就是特征之间的组合。第二是预测目标的变化。第三不论是从内容源，还是文章风格，或者内容的反馈（评论，等互动行为）都有各自的限制，组合这些模型。最后就是空间变换，把特征变换到另外的 latent 语义空间尝试解决。

### **数据集**

此部分来自外网整理：作者：DilicelSten

原文：https://blog.csdn.net/Totoro1745/article/details/84678858

#### FakeNewsNet

下载链接：https://github.com/KaiDMML/FakeNewsNet

说明：该数据集包含新闻内容和正确标注真假新闻标签的社会语境特征。

使用论文：

（1）A Stylometric Inquiry into Hyperpartisan and Fake News

（2）Exploiting Tri-Relationship for Fake News Detection

#### BuzzFeedNews

链接：https://github.com/BuzzFeedNews/2016-10-facebookfact-check/tree/master/data

说明：该数据集包括完整的Facebook新闻发布于接近2016年美国大选从9月19日到23日以及9月26日和27日。

#### LIAR

链接：http://www.cs.ucsb.edu/~william/software.html

说明：该数据集是从PolitiFact收集，包括简短陈述，例如新闻稿，电视

或电台采访，竞选演讲等，并包含元数据。

使用论文：

（1）“Liar,LIar Pants on Fire”:A New Benchmark Dataset for Fake News Detection

（2）Multi-Source Multi-Class Fake News Detection

#### BS Detector

链接：https://github.com/bs-detector/bs-detector

说明：为新闻浏览器导出的数据集，包含新闻内容和正确标注真假新闻标签。

#### CREDBANK

链接：http://compsocial.github.io/CREDBANK-data/

说明：[推特](https://www.baidu.com/s?wd=推特&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)的大数据集，包含新闻内容和人工标注标签。

数据集涉及的内容如下：

#### Twitter and Weibo DataSet

链接：https://github.com/majingCUHK/Rumor_RvNN

http://alt.qcri.org/˜wgao/data/rumdect.zip

说明：5000条言论带着500w的转发量

使用论文：

（1）CSI: A Hybrid Deep Model for Fake News Detection

（2）Detecting rumors from microblogs with recurrent neural network

（3）Early Detection of Fake News on Social Media Through Propagation Path Classification with Recurrent and Convolutional Networks

#### Twitter15 Twitter16

链接：https://www.dropbox.com/s/7ewzdrbelpmrnxu/rumdetect2017.zip?dl=0

说明：谣言数据

使用论文：

Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning

#### 推特语料

链接：http://www.cs.jhu.edu/svitlana/

说明：具体时间事件所搜集的数据集

使用论文：

Separating Facts from Fiction Linguistic Models to Classify Suspicious and Trusted News Posts on Twitter

#### 包含图的假新闻数据集

链接：https://drive.google.com/open?id=0B3e3qZpPtccsMFo5bk9Ib3VCc2c

说明：文本+图像

使用论文

TI-CNN: Convolutional Neural Networks for Fake News Detection

#### 谣言数据集

链接：http://mia.kaist.ac.kr/publications/rumor.

说明：数据集包含三个维度：时间，结构和语言

使用论文：

Prominent features of rumor propagation in online social media

### **相关论文介绍**

在工业界比如互联网公司解决该类问题主要还是通过构建 pipeline，融合多个模型：内容向模型集，用户向模型集，结合号主发布者特征，内容产生的用户行为特征等综合构建一套体系进行解决。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-025640.jpg)

我们在实际控制的时候结合了几十个静态 + 动态特征模型和知识库进行召回 pop 人工验证。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-025907.jpg)

然而和工业界处理问题不同的是，顶会的相关论文主要根据数据集的特点，通过单模型进行建模解决。**主要的参考的维度有：**1）内容本体 ；2）内容生产源（源，内容发布者）；3）内容阅读者（用户）及其行为（订阅，评论）三大类，多个小类的特征进行融合处理。

比如通过端到端的深度学习，基于概率分布的特征挖掘，构建新颖的综合类目标函数等大一统的方式进行尝试解决。很多模型往往只能在小规模数据集上进行实践。我们介绍几篇学术领域相关较新论文。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-030111.jpg)

**这篇是 CIKM 2017 的 long paper。**作者认为通过构建社交图谱并不便利，构建一些假新闻的特征也需要大量人工知识。文章认为之前的检测方法不能很好的一次整合正文（text），反馈（response），源（source）三者的特征。论文的数据集来自 twitter 和 weibo，weibo 中的正文就是讨论的某个话题，而非一般的文章，反馈就是主题参与者的回复，源就是回复的用户。

整个架构由两个部分组成：**Capture 模块**用于提取一篇正文所有的反馈文本信息，通过 LSTM 来组装多个回复内容。 **Scoure 模块**通过构建用户关系网络降纬后计算得到一对si和y^i ，si用于后续网络计算，y^i 也可用于单独的用户分析。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-030718.jpg)

如上图的 Capture 部分用来抽取文章和用户的低维度表示 ，用一个 RNN 来抽取正文（text）的向量。

![image-20200314110925486](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-030926.png)

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-030941.jpg)

这篇是中科院计算机研究所的金志威和曹娟博士的研究工作，发表在 AAAI 2016。

**Step 1：作者通过一个 Topic 模型来进行冲突的观点挖掘。**

通过对发帖的支持和反对行为构造信用网络（Credibility NetWork），作者认为每一个帖子（tweet）都是由一组混合的主题 topic，和对某个特定主题 topic 多种观点 viewpiont 组成。 每一个主题-观点（topic-viewpoint ）pair，它的分布参数来自 Dirichlet 分布

![[公式]](https://www.zhihu.com/equation?tex=\phi_{kl}\sim+Dir(\beta)) 。k 表示 topic 维度，l 表示 viewpoint 维度。

\1. 每一个帖子，组成它的所有 topic，符合一个参数为 θt 的 Dirichlet 分布 ![[公式]](https://www.zhihu.com/equation?tex=\theta_{t}\sim+Dir(\alpha)) 。

\2. 同样对所有可能的 topic，组成它的所有的 viewpoint 同样符合一个参数为 ψtk 的 Dirichlet 分布。

然后怎么生成文章呢，就是通过 θt 为参数的多项式分布中得到主题，从 ψtk 的多项式分布中得到观点 Vtn，由于这里已经确定了 ψtk 的 k，就是主题 k=Ztn，所以就是 ![[公式]](https://www.zhihu.com/equation?tex=\psi_{tz_{tn}}) ，l 就是 Vtn。

那最终一个 tweet 的 topic-viewpoint 生成的参数 Φkl 就可以写成 ![[公式]](https://www.zhihu.com/equation?tex=\phi_{z_{tn}}v_{tn}) ，就是产生自多项式分布 ![[公式]](https://www.zhihu.com/equation?tex=w_{tn}\sim+Mult(\phi_{z_{tn}}v_{tn})) 。

如果一个来自同一个主题下面的多个主题-观点 pair，之间距离非常大（设定值h） 。距离采用 Jensen-Shannon Distance（JSD），其实 JSD 是 KL Divergence（Dkl）的等价模式。

**具体冲突观点挖掘如下：**

\1. 对一个新闻数据集建模，生成大量的 topic-viewpoint pair；

\2. 比较同一个 topic 生成的 topic-viewpoint 对的 JSD，建立链接关系；

\3. 用 Wagstaff et al 2001 提到的带限制的 K-means 算法，把某个 topic 下的 viewpoint 观点聚合成两个彼此冲突的堆。

接下来就是信用网络的定义。根据上面的主题模型挖掘，我们已经有了参数 θt（主题）和ψtk（观点），就可以得到一个 tweet t 在 topic k 上的 viewpoint l 观点为：![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055008.jpg)

两两 tweet 的函数值定义为

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055025.jpg)

Djs 表示 Jensen-Shannon 距离。wij 就是 f(ti,tj) 的矩阵。

文中定义 loss function 如下：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055042.jpg)

其中 ![[公式]](https://www.zhihu.com/equation?tex=T%3D\left\{+C(t_{1})%2C...%2CC(t_{n})+\right\}) 的 C(ti) 表示 tweet ti 的信用值，是需要学习的参数。 具体求导和证明网络可收敛过程可以参考论文，最终得到每 k 轮迭代的表达式：![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055058.jpg)



![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055108.jpg)

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055140.jpg)

论文开始先通过大量数据分析挖掘，发现帖子内容，作者和主题三者和新闻的真假有很强的关联性。于是把三者放入一个深度扩散网络中 ，同时最小化三者的目标。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055153.jpg)

论文通过学习显式特征（Explicit）和潜在特征（Latent），潜在特征通过 GRU 的 Hidden 层和 Fusion 层得到：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-55247.jpg)

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055246.jpg)

论文提出了一个 GDU 单元，不仅可以针对帖子正文，还可以对作者，主题同时进行学习。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055355.jpg)

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055353.jpg)

其中，作者的 L(Tu) 如下：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055354.jpg)

其他的 L(Tn) L(Ts) 是一样的形式。

最终的网络架构三者相互连接起来如下图：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055403.jpg)

论文和其他方法进行了对比。整个方法有点类似图神经网络。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-055842.jpg)

这篇文章中了 WSDM '19 ，个人认为创新性很高。把作者（或者是发布者），新闻，社交网络的用户，和用户直接的订阅行为，构建了 5 个矩阵。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-060441.jpg)

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-60444.jpg)

新闻内容矩阵；用户矩阵；用户-新闻行为矩阵，作者-新闻发布关系矩阵。其中新闻内容矩阵，和用户矩阵，采用 NMF 进行分解。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-060442.jpg)

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-60442.jpg)

用户-新闻行为矩阵分解的目标是：高信用分的用户偏好分享真实新闻，低信用分用户偏好分享假新闻。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-060443.jpg)

作者-新闻发布关系矩阵分解的目标：基于新闻发布者的潜在特征，可以通过他发布的行为得到。文章把新闻发布者分为各种党派风格 o ，然后用分解后的矩阵拟合这个特征。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-060444.jpg)

通过和 Hadamard 正交矩阵做运算 ⊙ 来衡量误差大小。

最后通过把刚刚几个矩阵得到的分解矩阵进行运算，最终目标是：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-060446.jpg)

把所有的矩阵分解目标和最终目标拼接起来就得到的整体目标函数：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-060445.jpg)

具体求导过程需要一定数学知识，对这篇论文有兴趣的同学可以看原文。

### **相关比赛**

Dean Pomerleau 和 Delip Rao 在 2017 年举办了假新闻挑战：*Exploring how artificial intelligence technologies could be leveraged to combat fake news.*

**比赛地址：**[http://www.fakenewschallenge.org/](https://link.zhihu.com/?target=http%3A//www.fakenewschallenge.org/)

训练样本和预测输入都是一个长事件标题和一段正文内容。输出的目标是正文内容是对标题的：1）赞同，2）反对，3）讨论，4）不相关。

组委会认为，观点检测任务和假新闻任务场景是有强相关的，仅仅相关或不相关会比较容易。通过正文来分析观点是否赞同标题的内容陈述。第一名采用了深度卷积神经网络和 GBDT 两个模型。第二名采用了多种模型得到特征（如 NMF，LDA ，LSI，unigrams 等等）加上多层 MLP。这次比赛其实只能算假新闻领域的一个子问题的尝试。

***[Andreas Hanselowski, 2018]*** 这篇 COLING 的 Long Paper 中作者对这次比赛的前三名的方法和特征表现进行了分析，提出了自己的改进方案，取得了该任务 state-of-the-art 的表现。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-060831.jpg)

他们的框架把语义信息特征通过 stackLstm 表征，再加上对标题和正文的特征融合，实验表现在小样本的类别上有明显提升。

### 参考文献

[1] 一文看懂虚假新闻检测（附数据集 & 论文推荐）https://zhuanlan.zhihu.com/p/57124028

[1]. Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J. Smola, Le Song. "Variational Reasoning for Question Answering with Knowledge Graph". arXiv preprint arXiv:1709.04071, 2017.

[2]. Zhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. "News Verification by Exploiting Conflicting Social Viewpoints in Microblogs". AAAI 2016.

[3]. Kai Shu, Suhang Wang, Huan Liu. "Beyond News Contents: The Role of Social Context for Fake News Detection". WSDM 2019.

[4]. Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, Huan Liu. "Fake News Detection on Social Media: A Data Mining Perspective". SIGKDD 2017.

[5]. William Yang Wang. “Liar, Liar Pants on Fire”: A New Benchmark Dataset for Fake News Detection. ACL 2017.

[6]. Natali Ruchansky, Sungyong Seo, Yan Liu. "CSI: A Hybrid Deep Model for Fake News Detection". CIKM 2017.

[7]. Andreas Hanselowski, Avinesh PVS, Benjamin Schiller, Felix Caspelherr, Debanjan Chaudhuri, Christian M. Meyer, Iryna Gurevych. "A Retrospective Analysis of the Fake News Challenge Stance Detection Task". arXiv preprint arXiv:1806.05180, 2018.

[8]. Benjamin D. Horne, Sibel Adali. "This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News". ICWSM 2017.

# 多模态内容理解算法在新闻检测中的应用

## 1. 背景

   随着互联网的普及，用户的生活方式也发生了很大改变，现今社会中，我们从互联网上获取的信息越来越多。2018年顶级国际期刊《科学》指出，在2016年美国总统大选期间样本选民平均每人每天要接触4篇假新闻；要传播至1500个选民，假新闻的速度是真实新闻的6-20倍。因此利用人工智能的方式对新闻真实性作自动测评，对限制谣言传播有很大益处。以互联网为载体，新闻通常包括文本、图片、短视频等内容信息，同时还有新闻和用户的属性特征，本文介绍一种利用多模态数据增强虚假新闻检测对方法，数据来源为[1]。

## 2. 问题描述

   多模态信息融合通常包含各模态数据特征提取、特征融合、决策三个模块，其中特征提取是对图像、文本等数据，用与训练好的模型进行提取样本的全局特征，以便后续融合。在特征融合部分，对各模态特征进行统一化。决策则是训练以任务输出为目标（如分类标签）的模型。神经网络具有强大特征抽象功能，因此特征融合和决策（分类器训练）通常可以同时进行，即网络以不同模态特征作为输入，任务结果作为输出。新闻检测过程如图1所示，后文将分别介绍各部分的实现细节。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-062819.png)

## 3. 特征提取

   公开数据集[1]中，每条样本包括9种数据：文本、图像id、新闻类型、userGender、userFollowCount、userFansCount、userWeiboCount、userLocation、userDescription，此外每条样本有唯一的id，训练时每条id有二值标签，0表示真实新闻，1表示虚假新闻。其中文本不为空，图像id可能为空或多个，其他属性可能为空（nan）。

提取特征时，将上述数据分为四种类型，下面分别介绍不同类型数据提取方式。

   1）文本数据：作为新闻内容理解的主要模态，我们采用bert工具，用chinese_L-12_H-768_A-12提供对预训练模型和词库对每条文本提取sentence_embedding，最终每条文本被映射为768维向量。

 2）图像数据：与文本类似，图像数据也包含了内容相关的语义数据，我们采用alexnet结构，和其在imagenet-1000的预训练模型对图像特征进行提取。

 3）静态属性：属性包括两个子类，第一种是新闻类型、userGender和userLocation，这些属性是有限的离散值，因此我们将根据值域的范围，将其映射为one-hot向量，然后收尾相连。需要注意的是，测试数据的属性可能出现新的属性取值，则对应的向量是0。例如：训练集中城市属性是「北京，上海，广州」，对应的one-hot特征是[1 0 0]，[0 1 0]，[0 0 1]，测试时城市属性出现了深圳、杭州，则这些新属性均为[0 0 0]。这样做是因为训练时网络只会对已有信息进行响应，而无法对未知信息做判断。如果离散属性之间有相关性，例如城市间的相关性用距离度量，则可以用先验信息进行修正，这样深圳可能是[0 0.1 0.9]，杭州是[0 0.8 0.2]。

第二类属性包括三个属性：userFollowCount、userFansCount和userWeiboCount，这些属性的值域理论上是无限的，且数值具有一定意义。这里我们先对数据进行聚类，具体做法是将三个属性看作三维向量，用kmeans聚成N类，然后每条样本映射到对应的类别，最后将N个类别编号映射为one-hot特征。这样做的好处是能够将属性统一编码为one-hot特征，同时对过大或过小的数据也能将其归为相近的类别中。

   4）userDescription：该属性较为特殊，是用户的属性描述，但数据本质上是文本信息，我们采用与文本数据相同的处理方式提取768维的sentence_embedding。在融合时，单独当作一个模态考虑。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-063303.png)

图2 不同模态数据特征表征示意

## 4. 多模态内容理解

  对各类型数据进行特征提取后，需要用多模态学习的方法将这些特征关联起来。多模态学习根据融合对象的不同，可分为特征层的融合和分数层的融合，特征层是以上一节中的特征为输入，构建模型。分数层通常是对各模态数据都训练模型，然后将分类预测的概率向量作为输入，再训练统一的分类器。由上一节分析可知，新闻中的模态并不是完全等同的，新闻内容直接由文本描述，图片也与新闻内容有较大相关性，这两中模态可以直接训练分类器。而其他属性则是对用户和新闻的描述，和新闻内容不一定有直接关系，这些模态则不适合训练分类器。因此我们主要探究特征层面的融合，对于分数层融合，我们尝试了一种不同的处理方式，对统一特征训练多个分类器，将这些分类器预测的分数进行融合，可以看作是一种特殊的投票方式。下面分别介绍这两种方法。

### 4.1 特征级的多模态学习

   我们首先采用[2]中的两种特征融合方法，对四种模态特征分别进行多层全连接计算，得到相同尺寸的向量，然后进行向量拼接（concatenate）或逐元素点乘（pairwise product）操作。图3是以三种模态（文本特征、图像特征和用户描述特征）为例的特征层融合示意图。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-063433.png)          ![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-063434.png)

图3 三种模态的特征层融合方式及其对应的网络结构。（a）拼接连接，（b）点乘连接。 

分析这两种网络结构可知，拼接连接能够完整保留各通道的信息。而点乘连接可以看作是计算各通道的相关性，当各通道在某一维响应都较大时才有值，如果其中有一个模态在256维向量中某一维数值较小，则融合后整体在这一维的数值会很小。我们在此基础上提出一种新的融合结构，记为混合（mix）连接，同时保留各模态独立信息和互相关信息，其结构如图4所示：

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-063625.png)     ![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-063624.png)

图4 两种mix结构设计方式。（a）三元组点乘（记为mix-1），（b）多个二元组点乘（记为mix-2）

   混合连接保留了所有信息，可以避免某一个模态的256维向量在某一维数值较小，造成其他模态信息的丢失。同时，mix结构可以避免梯度消失的情况。当模态数大于2时，相关项可以有不同表示，因此混合连接也有多种方式，我们提出两种不同的方式，分别如图4(a)和图4(b)表示。mix-1结构就是图3的两种方式混合，其优点在于连接后维度随模态数线性增长。缺点是当模态数很多时，相关项数值的数量级会有明显的变化，例如如果我们采用Batch normalization将feature map控制在0～1之间，则相关项很可能接近0，进而退化为拼接连接；如果feature map的值可能大于1，则相关项数量级可能会大大增加。mix-2中相关项是由各模态两两点乘得到的，因此可以避免相关项乘积过小的情况，而且考虑了任意两模态之间的相关性。但是mix-2连接后的长度与模态数的平方呈正比，当模态较多是会出现特征过长的情况。这两种方法各有优缺点，可根据实际情况设计需要的结构。

### 4.2 分数级的多模态学习

   多模态学习的另一种常用方法是对分数级的融合，通常做法是用每个模态训练分类器，然后将各分类器预测的分数进行融合。由前文分析可得，新闻内容识别中各个模态的内容不是对等的，只有文本和图像是对内容的描述，而且并不是每条文本都包括图像。因此我们尝试训练多个分类器，再将分类器的预测结果进行分数层的融合。

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-063901.png)

图5 多个预测模型的联合

   分数级的多模态学习是将预测的分数向量作为特征进行学习，我们这里采用多个分类器，对预测分数拼接后再通过分类器获得最终的预测结果，本质可以看作是用多个分类模型的预测值进行综合，最简单的决策方式可以采用投票。

## 5. 实验结果

   我们利用公开比赛数据集[1]对算法进行验证，数据集有超过38000条新闻，对应总图片数超过34000张，其中一个新闻可能包括多张图片，每个图片也可能被多条新闻索引。当不使用图片时，我们将每条新闻作为一个样本，将数据划分为10份，其中9份作为训练数据，1份作为验证数据。为测试模型泛化能力，我们采用交叉验证的方法，测试10次，每次取不同的数据集作为测试集。当使用图片时，我们只取包含图片的新闻，将每张图片和其他信息组成一个样本对，训练和测试集划分相同。

   首先我们测试不同模态对分类准确率的影响，由上文分析可知，数据集的构成与是否使用图片有关，因此实验中我们分别进行对比。表1展示文本、描述、属性的组合对结果对影响。

表1 特征级多模态新闻检测准确率（不包含视觉模态）

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-064038.png)

由表1可知多模态特征融合的效果要优于只用文本的效果，采用三个模态的效果最好。同时，属性属性对准确率的提升效果要优于用户描述模态。此外，在实验时我们发现，加入userFansCount、userFollowCount、userWeiboCount聚类映射的one-hot特征后，效果反而略微下降，因此属性只包含类型、性别和地点这三个离散属性，如何合理的使用数值化的属性提升分类效果可以作为后续的思考。表2是加入视觉模态组成样本对的测试结果。

表2 特征级多模态新闻检测准确率（包含视觉模态）

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-064131.png)

随着模态数量增多，预测的准确率也响应提升。表3展示了相同模态组合时，不同结构的影响。

表3 不同结构的检测准确率

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-064234.png)

表3显示，在验证集中concatenate的性能要优于pairwise product，我们提出的mix-2结构要优于其他形式的特征融合。在比赛实际测试时，mix-1和mix-2均要优于单一的融合方式，分析数据我们发现，训练集中样本有一定重复性，即样本的文本内容是相同的。因此验证集和测试集分布可能存在一定偏差，模型可能出现过拟合现象，因此实际应用时可根据问题和数据的特点，选择合适的融合结构。最后测试分数级的融合，结果如表4所示。

表4 分数级融合的分类准确率

![img](http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/2020-03-14-064302.png)

可以看到，分数级的融合效果在验证集上要优于特征级的融合。但是，在实际测试时同样结果会下降，分析原因，我们认为同样可能出现了过拟合的现象，因此在实际问题中可根据情况进行选择。

#[基于BERT和CNN的多模型虚假新闻分类](https://www.biendata.com/models/category/3529/L_notebook/)







